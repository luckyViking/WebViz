<!DOCTYPE html>
<html>
<head>
    <title>Support Vector Machines</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <!--<link rel="stylesheet" href="../css/bootstrap.min.css">-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <!--<link rel="stylesheet" type="text/css" href="../css/font-awesome.min.css">-->
    <link rel="stylesheet" type="text/css" href="../css/styles.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <!--<script type="javascript" src="./js/jquery.min.js"></script>-->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <!--<script type="javascript" src="./js/bootstrap.min.js"></script>-->
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script async>
        $(document).ready(() => {
            import("../js/svm.js").then(svm => loadPlotly(svm, $('#datasets').val(), $('#kernel').val(), $('#epsilon').val(), $('#c').val(), $('#style').val()));
            let currentExp = 0;

            let loadExplanation = function (id) {
                id = id % 6; // ToDo: replace with number of explanations.

                let currentActiveExp = $('.explanation.active');
                currentActiveExp.fadeOut(1000);
                currentActiveExp.removeClass('active');

                let newExp = $('#exp' + id);
                newExp.fadeIn(3000);
                newExp.addClass('active');

                $('.point').css('background-color', 'white');
                $('.point[data-target=' + id + ']').css('background-color', 'orange');
            };

            loadExplanation(currentExp);

            $('#forwards').click(function (e) {
                e.preventDefault();
                currentExp += 1;
                loadExplanation(currentExp);

            });

            $('#reload').click(function (e) {
                e.preventDefault();
                currentExp = 0;
                loadExplanation(currentExp);
                import("../js/svm.js").then(svm => loadPlotly(svm, $('#datasets').val(), $('#kernel').val(), $('#epsilon').val(), $('#c').val(), $('#style').val()));
            });

            $('.timelineText').click(function (e) {
                e.preventDefault();
                currentExp = parseInt($(this).attr('data-target'));
                loadExplanation(currentExp);
            });
        })
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <script>
        MathJax = {
            tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]},
            svg: {fontCache: 'global'}
        };
    </script>
</head>
<body>
<div class="col-lg-12" style="height:30px; text-align: left;">
    <a href="views.html" class="previous">&laquo; Views</a>
</div>

<div class="jumbotron text-center">
    <h1>Support Vector Machines</h1>
    <p>A Visualization</p>
</div>

<div class="container">
    <div class="row">
        <div class="introduction">
            <h2>Introduction</h2>
            <p>This website was created as part of the digitalization project "Webtools for teaching" at <a
                    href="https://www.frankfurt-university.de/en/" target="_blank">Frankfurt University of Applied
                Sciences (FRA UAS)</a>. "Computer-based visualization systems provide visual representations of datasets
                designed to help people carry out tasks more effectively." External representation replaces cognition
                with perception. We hope that our interactive visualization will make the SVM easier to understand for
                you.</p>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12 col-lg-9 text-center">
            <div class="scatter" id="plot"></div>
        </div>
        <div class="col-md-12 col-lg-3">
            <form class="form-horizontal" action="">
                <h3>SVM Settings</h3>
                <div class="form-group">
                    <label for="datasets" class="control-label col-sm-3">Dataset</label>
                    <div class="col-sm-9">
                        <select id="datasets" name="datasets" class="form-control input-sm">
                            <option value="iris">Iris</option>
                            <option value="salmon">Salmon</option>
                        </select>
                    </div>
                </div>
                <div class="form-group">
                    <label for="kernel" class="control-label col-sm-3">Kernel</label>
                    <div class="col-sm-9">
                        <select id="kernel" name="kernel" class="form-control input-sm ">
                            <option value="linear">Linear</option>
                            <option value="polynomial">Polynomial</option>
                            <option value="rbf">Radial Basis Function</option>
                        </select>
                    </div>
                </div>
                <div class="form-group">
                    <label for="epsilon" class="control-label col-sm-3">Epsilon</label>
                    <div class="col-sm-9">
                        <input type="number" name="epsilon" id="epsilon" value="0.001" class="form-control input-sm"/>
                    </div>
                </div>
                <div class="form-group">
                    <label for="c" class="control-label col-sm-3">C</label>
                    <div class="col-sm-9">
                        <input type="number" name="c" id="c" value="10" class="form-control input-sm"/>
                    </div>
                </div>
                <hr/>
                <div class="form-group">
                    <label for="style" class="control-label col-sm-3">Style</label>
                    <div class="col-sm-9">
                        <select name="style" id="style" class="form-control input-sm">
                            <option value="lines">Lines</option>
                            <option value="heatmap">Heatmap</option>
                        </select>
                    </div>
                </div>
                <hr/>
                <div class="form-group">
                    <div class="col-sm-6">
                        <button type="button" id="reload" class="form-control btn btn-success"><i
                                class="fa fa-refresh"></i> Reload
                        </button>
                    </div>
                    <div class=" col-sm-6">
                        <button type="button" id="forwards" class="form-control btn btn-primary"><i
                                class="fa fa-arrow-right"></i> Forwards
                        </button>
                    </div>
                </div>
                <div class="form-group">
                    <div class="col-sm-12">
                        <h3>Values</h3>
                        <ul id="values"></ul>
                    </div>
                </div>
            </form>
        </div>
    </div>

    <div class="row">
        <ol class="timeline">
            <li>
                <a class="timelineText" data-target="0" href="#">Why?</a>
                <span class="point" data-target="0"></span>
            </li>
            <li>
                <a class="timelineText" data-target="1" href="#">How?</a>
                <span class="point" data-target="1"></span>
            </li>
            <li>
                <a class="timelineText" data-target="2" href="#">Parameters</a>
                <span class="point" data-target="2"></span>
            </li>
            <li>
                <a class="timelineText" data-target="3" href="#">References</a>
                <span class="point" data-target="3"></span>
            </li>

        </ol>
    </div>

    <div class="row">
        <div class="col-md-12 col-lg-12">
            <div class="explanation" id="exp0">
                <h2>Why SVM?</h2>
                <p>
                    The Support Vector Machine (SVM) is one of the most modern technique used for regression-and
                    classification problems.
                    The SVM is a supervised learning model.
                    In this approach we are given a set of input vectors ($x_n$) paired with corresponding target values
                    ($t_n$).
                    The goal is to "learn" a model made out of these training set to make correct predictions of t for
                    newly
                    presented input data $x$.
                    In classification, $t$ is discrete and represented as class labels.
                    In regression $t$ is a continuous variable. The prediction $y(x,w)$ is expressed as the following
                    linear
                    model:
                    $$y(x,w) = \sum_{m=0}^{M} w_m \phi_m(x) = w^T\phi \label{ref1}$$
                    Here, $\phi_{m}(x)$ are basis functions and the parameters ${w_m}$ are the associated weights.
                </p>
            </div>
            <div class="explanation" id="exp1">
                <h2>How SVM works</h2>
                <p>
                    There are different types of the SVM: in the classification case, there is the original one the
                    Maximal
                    Margin Classifier, the kernelized version, the soft-margin version and the soft-margin kernelized
                    version which combines the first 3 versions and is used most frequently.
                    In the regression case there is the Support Vector Regression (SVR).
                    However, all SVMs are basically a specialization of (\ref{ref1}) and make predictions based on the
                    following function:
                    $$y(x,w)=\sum_{i=1}^{N}w_{i}K(x,x_i)+w_0 \label{ref2}$$
                    where K stands for kernel functions.
                </p>
                <p>
                    The SVM searches for the optimal hyperplane that best separates the data by maximizing the margin.
                    Maximizing the margin is an optimization problem that is equivalent to minimizing the norm of the
                    weight
                    vector:
                    $$minimize_{w,b} \space \frac{1} {2} ||w||^2 $$
                    subject to $$y_{i}(w * x_{i} + b)-1 \geq 0, \space i=1,...,m \label{ref3}$$
                    The convex quadratic optimization problem from (\ref{ref3}) can be solved by lagrange multipliers:
                    $$\mathcal{L}(w,b,\alpha) = \mathcal{f}(w)-\sum_{i=1}^{m}\alpha_{i}g_{i}(w,b)$$
                    $$\mathcal{L}(w,b,\alpha) = \frac{1}{2}||w||^{2}-\sum_{i=1}^{m}\alpha_{i}[y_{i}(w*x_{i}+b)-1]$$
                    $$\min_{w,b} \space \max_{a} \mathcal{L}(w,b,\alpha)$$
                    subject to
                    $$\alpha_{i}\geq0, \space i=1,...,m \label{ref4}$$
                    The problem from (\ref{ref4}) can then be rewritten in dual form and becomes a Wolfe Dual Problem.
                    In this way the parameters $w$ and $b$ can be found:
                    $$w=\sum_{i=1}^{m}\alpha_{i}y_{i}x_{i} \label{ref5}$$
                    $$b=y_{i}-w*x_{i} \label{ref6}$$
                </p>
                <p>
                    Because (\ref{ref4}) contains inequality constraints, the solution must fulfill certain conditions,
                    the
                    Karush-Kuhn-Tucker (KKT) conditions.
                    These conditions are: stationarity-, primal feasibility-, dual feasibility- and complementary
                    slackness
                    condition.
                    $$\alpha_{i}[y_{i}(w*x_{i}+b)-1]=0 \space for \space for \space all \space i=1,...,m \label{ref7}$$
                    The fourth one, the complementary slackness condition from (\ref{ref7}), says either $\alpha_{i}$ or
                    the
                    original condition should be zero.
                    <strong>The support vectors are the ones that have a positive $\alpha_{i}$ which means the second
                        condition is active.</strong>
                    If a solution meets the four KKT conditions, this solution is optimal.
                    However, unclean data, for instance outliers, are not uncommon and impair linear separability.
                    Vapnik and Cortes modified the original SVM to the <strong>Soft Margin SVM</strong> which means, in
                    the
                    classification case, <strong>outliers are allowed</strong>.
                    The original optimization problem from (\ref{ref3}) has been changed to (\label{ref8}):
                    the slack variable $\zeta$ and the hyperparameter $C$ have been added.
                    Regarding to this, the outliers can now be on the "wrong side" but a hyperplane can still be found.
                    $$minimize_w,b,\zeta \space \frac{1}{2}||w||^{2} + C \sum_{i=1}^{m} \zeta_{i} \label{ref8}$$
                    subject to
                    $$y_{i}(w*x_{i}+b) \geq 1-\zeta_{i}$$
                    $$\zeta_{i} \geq 0 \space for \space any \space i=1,...,m $$
                    The hyperparameter $C$ can then be used to control how the SVM should deal with outliers.
                </p>
            </div>
            <div class="explanation" id="exp2">
                <h2>Parameters</h2>
                <p>
                    When changing the parameters, see that when you want to apply a larger <b>C</b>, often a smaller
                    <b>&epsilon;</b> is required and vice versa.In many cases, a bad combination of the two parameters
                    will
                    result in not seeing the decision boundary, as they move outside the plotting domain.

                <h3>Epsilon &epsilon;</h3>
                Intuitively, the <b>&epsilon;</b> parameter defines how far the influence of a single training example
                reaches, with low values meaning ‘far’ and high values meaning ‘close’.
                The <b>&epsilon;</b> parameters can be seen as the inverse of the radius of influence of samples
                selected by
                the model as support vectors.
                When <b>&epsilon;</b> is very small, the model is too constrained and cannot capture the complexity or
                “shape” of
                the data. The region of influence of any selected support vector would include the whole training set.
                The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the
                centers of high density of any pair of two classes.<br>
                <b>Keep &epsilon; between 0.001 and 1</b>

                <h3>C</h3>
                The <b>C</b> parameter trades off correct classification of training examples against maximization of
                the decision function’s margin. For larger values of <b>C</b>, a smaller margin will be accepted if the
                decision function is better at classifying all training points correctly.
                A lower <b>C</b> will encourage a larger margin, therefore a simpler decision function, at the cost of
                training accuracy. In other words: C behaves as a regularization parameter in the SVM.
                As you can see when applying larger values for C, the support vectors move farther away from the
                decision boundary. Support vectors are displayed as X's.


                <ul id="centeredUL" style="margin-top: 10px">
                    <li><i><b>Small C</b></i> makes the constraints easy to ignore which leads to a large margin.</li>
                    <li><i><b>Large C</b></i> allows the constraints hard to be ignored which leads to a small margin.
                    </li>
                    <li>For <i><b>C = inf</b></i>, all the constraints are enforced.</li>

                </ul>

                <b>Keep C between 1 and 10000</b>

                </p>

            </div>
            <div class="explanation" id="exp3">
                <h2>References</h2>
                <ul>
                    <li><a href="https://www.syncfusion.com/ebooks/support_vector_machines_succinctly"
                           target="_blank"><i>Support Vector Machines Succinctly</i> by Alexandre Kowalcyzk</a></li>
                    <li><a href="https://papers.nips.cc/paper/1719-the-relevance-vector-machine.pdf" target="_blank">https://papers.nips.cc/paper/1719-the-relevance-vector-machine.pdf</a>
                    </li>
                    <li><a href="https://de.wikipedia.org/wiki/Support_Vector_Machine" target="_blank">https://de.wikipedia.org/wiki/Support_Vector_Machine</a>
                    </li>
                    <li><a href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"
                           target="_blank">https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html</a>
                    </li>
                </ul>
            </div>

        </div>
    </div>

    <hr>
    <footer>
        <p>Frankfurt University of Applied Sciences<br/>WebTools für die Lehre: SVM<br/><br/>Contributors:<br/>Yasemin
            Er; Hendrik Pfaff; Lukas Atkinson; Luca Jordan</p>
    </footer>
    <script src="../js/plotly_gui.js"></script>
</div>
</body>
</html>
